{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#_author_jeffrey_t\n",
    "#clean the OSM data for Sydney Metro Area:\n",
    "#https://mapzen.com/data/metro-extracts/your-extracts/c98c29b17741\n",
    "\n",
    "#import required libraries\n",
    "import xml.etree.cElementTree as ET\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "\n",
    "#some global refs\n",
    "osm_test_file = 'sydney_australia.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.9 MB\n",
      "{'node': 282039, 'nd': 359303, 'bounds': 1, 'member': 25166, 'tag': 241467, 'osm': 1, 'way': 49541, 'relation': 2094}\n"
     ]
    }
   ],
   "source": [
    "#print some basic stats about our file\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    from: http://stackoverflow.com/questions/2104080/how-to-check-file-size-in-python\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "file_info = os.stat(osm_test_file)\n",
    "print convert_bytes(file_info.st_size)\n",
    "\n",
    "def count_tags(filename):\n",
    "    # YOUR CODE HERE\n",
    "    p_evt = ('start',)\n",
    "    tags = {}\n",
    "    for _, elem in ET.iterparse(filename, events=p_evt):\n",
    "        my_tag = elem.tag\n",
    "        if my_tag in tags:\n",
    "            tags[my_tag] += 1\n",
    "        else:\n",
    "            tags[my_tag] = 1\n",
    "    return tags\n",
    "\n",
    "print count_tags(osm_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Fitzroy', 'Rd', 'Way', 'Highway', 'Road', 'Jones', 'Lane', 'Drive', 'St', 'Place', 'Circuit', 'Gardens', 'South', 'Square', 'Parade', 'Point', 'Esplanade', 'Boulevarde', 'Street', 'Crescent', 'Broadway', 'Avenue'])\n"
     ]
    }
   ],
   "source": [
    "#module to audit street names\n",
    "st_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "st_types = set() #defaultdict(set) ???\n",
    "\n",
    "def is_st_name(elem):\n",
    "    return (elem.attrib['k'].rstrip() == 'addr:street')\n",
    "\n",
    "def audit_st_type(street_types, street_name):\n",
    "    m = st_type_re.search(street_name)\n",
    "    if m:\n",
    "        this_st_type = m.group()\n",
    "        st_types.add(this_st_type)\n",
    "\n",
    "def list_st_types(filename):\n",
    "    p_evt = ('start',)\n",
    "    n = 0\n",
    "    for _, elem in ET.iterparse(filename, events=p_evt):\n",
    "        if elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if is_st_name(tag):\n",
    "                    audit_st_type(st_types, tag.attrib['v'])\n",
    "\n",
    "list_st_types(osm_test_file)\n",
    "print st_types\n",
    "\n",
    "#We can see that there are a few inconsistencies in naming which we should clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'addr:postcode': set(['200',\n",
      "                       '210',\n",
      "                       'NSW 1460',\n",
      "                       'NSW 2000',\n",
      "                       'NSW 2010',\n",
      "                       'NSW 2011',\n",
      "                       'NSW 2015',\n",
      "                       'NSW 2021',\n",
      "                       'NSW 2022',\n",
      "                       'NSW 2026',\n",
      "                       'NSW 2034',\n",
      "                       'NSW 2037']),\n",
      " 'is_in:country_code': set(['AU']),\n",
      " 'is_in:state_code': set(['NSW']),\n",
      " 'postal_code': set(['1465;2033',\n",
      "                     '2000',\n",
      "                     '2005',\n",
      "                     '2007',\n",
      "                     '2008',\n",
      "                     '2009',\n",
      "                     '2010',\n",
      "                     '2011',\n",
      "                     '2015',\n",
      "                     '2016',\n",
      "                     '2017',\n",
      "                     '2018',\n",
      "                     '2019',\n",
      "                     '2020',\n",
      "                     '2021',\n",
      "                     '2022',\n",
      "                     '2023',\n",
      "                     '2024',\n",
      "                     '2025',\n",
      "                     '2026',\n",
      "                     '2027',\n",
      "                     '2028',\n",
      "                     '2029',\n",
      "                     '2030',\n",
      "                     '2031',\n",
      "                     '2032',\n",
      "                     '2033',\n",
      "                     '2034',\n",
      "                     '2035',\n",
      "                     '2036',\n",
      "                     '2037',\n",
      "                     '2038',\n",
      "                     '2039',\n",
      "                     '2040',\n",
      "                     '2041',\n",
      "                     '2042',\n",
      "                     '2043',\n",
      "                     '2044',\n",
      "                     '2045',\n",
      "                     '2046',\n",
      "                     '2047',\n",
      "                     '2048',\n",
      "                     '2049',\n",
      "                     '2050',\n",
      "                     '2060',\n",
      "                     '2061',\n",
      "                     '2062',\n",
      "                     '2063',\n",
      "                     '2064',\n",
      "                     '2065',\n",
      "                     '2066',\n",
      "                     '2068',\n",
      "                     '2088',\n",
      "                     '2089',\n",
      "                     '2090',\n",
      "                     '2093',\n",
      "                     '2095',\n",
      "                     '2110',\n",
      "                     '2111',\n",
      "                     '2112',\n",
      "                     '2113',\n",
      "                     '2130',\n",
      "                     '2131',\n",
      "                     '2132',\n",
      "                     '2133',\n",
      "                     '2134',\n",
      "                     '2136',\n",
      "                     '2137',\n",
      "                     '2193',\n",
      "                     '2194',\n",
      "                     '2203',\n",
      "                     '2204',\n",
      "                     '2205',\n",
      "                     '2206',\n",
      "                     '2207',\n",
      "                     '2208',\n",
      "                     '2216',\n",
      "                     '2217',\n",
      "                     '2218',\n",
      "                     '2219',\n",
      "                     '2220',\n",
      "                     '2221',\n",
      "                     '2224',\n",
      "                     '2229',\n",
      "                     '2231']),\n",
      " 'source:addr:postcode': set(['knowledge']),\n",
      " 'source:postal_code': set(['Wikipedia',\n",
      "                            'knowledge',\n",
      "                            'local_knowledge',\n",
      "                            'wikipedia'])}\n"
     ]
    }
   ],
   "source": [
    "# audit postcodes - a field not covered in the case study\n",
    "postcode_re = re.compile(r'^\\d{4}$')\n",
    "postcode_flds = set()\n",
    "postcode_bad = set()\n",
    "\n",
    "# according to the osm documentation, there are a few postcode fields:\n",
    "# addr:postcode, boundary=postal_code\n",
    "\n",
    "def is_postcode(elem):\n",
    "    return (elem.attrib['k'].rstrip() == 'addr:postcode')\n",
    "\n",
    "def audit_postcode_fld(elem):\n",
    "    if elem.attrib['k'].find('code') != -1:\n",
    "        postcode_flds.add(elem.attrib['k'])\n",
    "\n",
    "postcode_types = defaultdict(set)\n",
    "def audit_postcodes(filename):\n",
    "    p_evt = ('start',)\n",
    "    n = 0\n",
    "    for _, elem in ET.iterparse(filename, events=p_evt):\n",
    "        for tag in elem.iter('tag'):\n",
    "            if is_postcode(tag):\n",
    "                pc = postcode_re.search(tag.attrib['v'])\n",
    "                if not pc:\n",
    "                    postcode_types[tag.attrib['k']].add(tag.attrib['v'])\n",
    "            else:\n",
    "                if tag.attrib['k'].find('code') != -1:\n",
    "                    postcode_types[tag.attrib['k']].add(tag.attrib['v'])\n",
    "\n",
    "audit_postcodes(osm_test_file)\n",
    "pprint.pprint(dict(postcode_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postcodes in NSW should all 4 numbers - here we can see that there are inconsistencies in our data with some postcodes having been prefixed with NSW, these will need to be cleaned. \n",
    "\n",
    "Some entries also seem to have postcodes stored under the field 'postal_code'. All but one of these entries (namely the one we have identified as '1465;2033') appear to be valide postcodes. For consistency, we will move these to 'addr:postcode'.\n",
    "\n",
    "We now compare any elements where both are present and see if there are any differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_postcodes(filename):\n",
    "    p_evt = ('start',)\n",
    "    n = 0\n",
    "    test_flds = set(['addr:postcode', 'postal_code'])\n",
    "    for _, elem in ET.iterparse(filename, events=p_evt):\n",
    "        #setup test variables for each tag\n",
    "        addr_postcode = False\n",
    "        postal_code = False\n",
    "        postcodes = {}\n",
    "        for tag in elem.iter('tag'):\n",
    "            tag_k = tag.attrib['k'].rstrip()\n",
    "            if tag_k == 'addr:postcode':\n",
    "                addr_postcode = True\n",
    "                postcodes['addr:postcode'] = tag.attrib['v']\n",
    "            elif tag_k == 'postal_code':\n",
    "                postal_code = True\n",
    "                postcodes['postalcode'] = tag.attrib['v']\n",
    "        if (addr_postcode and postal_code):\n",
    "            print postcodes\n",
    "\n",
    "compare_postcodes(osm_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there are no elements which contain both the 'addr:postcode' and 'postal_code' fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing tag types\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "lower_two_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def test_tag_type(elem):\n",
    "    tag_type = elem.attrib['k']\n",
    "    if lower.match(tag_type) != None:\n",
    "        keys['lower'] += 1\n",
    "    elif lower_colon.match(tag_type) != None:\n",
    "        keys['lower_colon'] += 1\n",
    "    elif lower_two_colon.match(tag_type) != None:\n",
    "        keys['lower_two_colon'] += 1\n",
    "        two_colon_set.add(tag_type)\n",
    "    elif problemchars.match(tag_type) != None:\n",
    "        keys['problemchars'] += 1\n",
    "    else:\n",
    "        keys['other'] += 1\n",
    "        others_set.add(tag_type)\n",
    "\n",
    "keys = {\n",
    "        'lower': 0,\n",
    "        'lower_colon': 0,\n",
    "        'lower_two_colon': 0,\n",
    "        'problemchars': 0,\n",
    "        'other': 0\n",
    "        }\n",
    "two_colon_set = set()\n",
    "others_set = set()\n",
    "\n",
    "def test_tag_types(filename):\n",
    "    p_evt = ('start',)\n",
    "    n = 0\n",
    "    test_flds = set(['addr:postcode', 'postal_code'])\n",
    "    for _, elem in ET.iterparse(filename, events=p_evt):\n",
    "        if 'k'  in elem.attrib:\n",
    "            test_tag_type(elem)\n",
    "\n",
    "test_tag_types(osm_test_file)\n",
    "print keys\n",
    "print two_colon_set\n",
    "print others_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tag types seem to be quite well maintained - we do not see any problem chars and there do not appear to be any two colon fields relevant to what we are attempting to extract. We note there may be on problematic other type - namely: 'addr:city_1'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to fix the identified gaps in our data\n",
    "Our goals are to:\n",
    "* Ensure that all the street names are uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set(['Court', 'Place', 'Way', 'Revesby', 'Walk', 'Highway', 'Ogilve', \n",
    "#'Promenade', 'Corination', 'Lane', 'Drive', 'St', 'Hilma', 'Circuit', 'Road', \n",
    "#'Square', 'Parade', 'Point', 'st', 'Street', 'Crescent', 'Ave', 'Avenue'])\n",
    "\n",
    "# From the sample above create a set of good street styles to check against.\n",
    "good_st_types = set([\"Court\",\n",
    "                    \"Place\",\n",
    "                    \"Way\",\n",
    "                    \"Walk\",\n",
    "                    \"Highway\",\n",
    "                    \"Promenade\",\n",
    "                    \"Corination\",\n",
    "                    \"Lane\",\n",
    "                    \"Drive\",\n",
    "                    \"Street\",\n",
    "                    \"Circuit\",\n",
    "                    \"Road\",\n",
    "                    \"Square\",\n",
    "                    \"Parade\",\n",
    "                    \"Point\",\n",
    "                    \"Crescent\",\n",
    "                    \"Avenue\"\n",
    "                    ])\n",
    "fix_st_dict = {\"St\": \"Street\",\n",
    "              \"st\": \"Street\",\n",
    "              \"Ave\": \"Avenue\",\n",
    "              \"ave\": \"Avenue\"\n",
    "              }"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
